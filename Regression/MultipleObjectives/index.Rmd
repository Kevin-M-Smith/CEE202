---
title: "Vignette: Regression Frontier"
author: ''
date: ''
output:
  html_document:
    fig_width: 10
    keep_md: yes
    self_contained: no
    theme: spacelab
    toc: yes
  pdf_document:
    toc: yes
---

<script type="text/javascript" src="js/jquery.min.js"></script>
<script type="text/javascript" src="js/jquery-ui.min.js"></script>
<script type="text/javascript" src="js/jquery.fancybox-1.3.4.pack.min.js"></script>
<script type="text/javascript" src="js/jquery.tocify.js"></script>
<script type="text/javascript" src="js/jquery.scianimator.min.js"></script>
<script type="text/javascript" src="js/page.js"></script>
<script>  </script>
<link type="text/css" rel="stylesheet" href="css/jquery.tocify.css" />
<link type="text/css" rel="stylesheet" media="screen" href="css/jquery.fancybox-1.3.4.css" />
<link type="text/css" rel="stylesheet" href="css/style.css"
<head> <div id="tableofcontents"></div> </head>
<div id="source" class="tocify"> 
<ul class="tocify-header nav nav-list">
<li class="tocify-item active" style="cursor: pointer;">
<a onclick='toggle_R();' >Show / Hide Source</a>
</li></ul>
</div>
__Kevin M. Smith // Environmental Statistics // Fall 2014__
<hr>

```{r, message = FALSE, echo = FALSE, dev = 'png'}
# Load Required Libraries
require(ggplot2)
require(nortest)
require(plyr)
require(stats)
require(lattice)
require(RColorBrewer)
require(doMC)
require(pander)

# Set Up Parallel Processing
registerDoMC(4)
```

<hr>
# Overview
The purpose of this short note is to explore the [Pareto frontier](http://en.wikipedia.org/wiki/Pareto_efficiency#Pareto_frontier) when there are multiple objectives. In this case the trade-offs are between $R_{pred}^2$ and the apparent normality of the leave-one-out residuals via the p-value of the [Anderson Darling test statistic](http://en.wikipedia.org/wiki/Andersonâ€“Darling_test). 
<hr>
## The Mystery Data
This note uses data of unknown origin, but that is clearly non-linear in it's untransformed state. In the following section a range of power transforms will be applied on $x$ and $y$ before fitting linear regressions of the form $(y_{transformed} = \beta x_{transformed} + \epsilon)$. 
<br><br>
 

```{r, fig.height = 6, fig.width = 6}
# Load in Data
mystery <- read.csv("data/mystery.csv", header=FALSE)

colnames(mystery) <- c("y", "x")

yyy <- unlist(mystery[1])
xxx <- unlist(mystery[2])

qplot(x = xxx, y = yyy) + xlab("x") + ylab("y") +
  ggtitle("Simple Scatterplot of the Untransformed Data")
```

> __See this [vignette on Tukey's bulging rule](http://kevin-m-smith.github.io/CEE202/Regression/BulgingDiagram/) or use [this interactive transform tool](http://kevin-m-smith.github.io/CEE202/Regression/SimpleTransformTool/) to get a better sense of the transformations that will be performed.__

<br>
<hr>
# Contour Plots 
<br>
```{r, message = FALSE, echo = FALSE, dev = 'png', cache = TRUE}
# Powers of X and Y to Search
pxx <- seq(-3, 3, length.out = 100)
pyy <- seq(-3, 3, length.out = 100)

# Place to Store Results
results <- expand.grid(px = pxx, py = pyy)

# Custom Regression Function
regression <- function(xp, yp){
  yy = mystery["y"]^yp
  xx = mystery["x"]^xp
  fit <- lm(yy~xx)
  
  hat.diagonal <- lm.influence(fit)$hat
  leave.one.out.residuals <- residuals(fit)/(1-hat.diagonal)
  press <- sum((leave.one.out.residuals)^2)
  ss.tot <- sum((yy-mean(yy))^2)
  pred.r2 <- 1 - (press/ss.tot)
  pred.ad <- ad.test(residuals(fit)/(1-hat.diagonal))$p.value
  
  adj.r2 <- summary(fit)$adj.r.squared
  ad <- ad.test(residuals(fit))$p.value
  
  res <- data.frame( 
    adj.r2 = adj.r2, 
    pred.r2 = pred.r2, 
    press = press, 
    ss.tot = ss.tot, 
    ad = ad, 
    pred.ad = pred.ad)
  
  return(res)
}

# Search the Space
results <- adply(results, 1, function(z) regression(z$px, z$py), .parallel = TRUE)
```

## $R_{pred}^2$
After running many regressions on variables subject to power transforms in the search space $t \in [-3, 3]$, a locally optimal region of the $R_{pred}^2$ can be identified between $t_x \in [-1.5, -2.7]$ and $t_y \in [1.7, 2.4]$, where $t_x$ and $t_y$ are the power transforms on $x$ and $y$ respectively.  

```{r, fig.height = 8, fig.width = 8}
levelplot(pred.r2~px+py, data = results, contour = TRUE, panel=function(...) {
  arg <- list(...)
  panel.levelplot(...)},
  col.regions=colorRampPalette(brewer.pal(9,"Blues")[1:8]),
  xlab = "Power Transform on X",
  ylab = list("Power Transform on Y", rot=90),
  main = "Prediction R Squared")
```

## Normality of LOO Residuals

Here the p-value of the Anderson-Darling test statistic is used as a surrogate measure for the apparent normality of the leave-one-out (loo) residuals. At first blush this may seem like a blatant abuse of the test statistic and a malignant use of a p-value. While I would concede the point if pushed on it, I think the apparent continuity in the search space $t \in [-3, 3]$ suggests that the p-value can innocently (i.e. soundly) assist in the identification of regions where the loo residuals _appear_ normal. In either case, the resulting contour plot is shown below. 

```{r, fig.height = 8, fig.width = 8}
levelplot(pred.ad~px+py, data = results, contour = TRUE, panel=function(...) {
  arg <- list(...)
  panel.levelplot(...)},
  col.regions=colorRampPalette(brewer.pal(9,"Blues")[1:8]),
  xlab = "Power Transform on X",
  ylab = list("Power Transform on Y", rot=90),
  main = "P-Value of Anderson Darling Test Statistic on LOO Residuals")
```


# Pareto Selection

The points on the Pareto frontier of $R_{pred}^2$ vs. the Anderson Darling p-value is shown for the upper-right-hand corner of the solution space. 

```{r, fig.width = 8, fig.height = 8}
g <- ggplot(results, aes(x = pred.ad, y = pred.r2)) + geom_point() + theme_bw()
g <- g + xlim(0.75, 1) + ylim(0.75, 1)

top.sorted <- arrange(results, pred.ad, pred.r2, decreasing = TRUE)
pareto.points = top.sorted[which(!duplicated(cummax(top.sorted$pred.r2))), ] 
g <- g + annotate("point", x=pareto.points$pred.ad, 
                  y=pareto.points$pred.r2, colour = "#e51843", size = 6)
g <- g + ggtitle("Prediction R-squared vs. Anderson-Darling P-value on \n Leave-One-Out Residuals with Pareto Frontier Highlighted")
g <- g + xlab("Anderson-Darling P-value on Leave-One-Out Residuals")
g <- g + ylab("Prediction R-squared on Leave-One-Out Residuals")
g

```

# Curve Fitting
The optimal transform is chosen according to the preferences assigned to the particular objectives. Choosing, for the sake of example, an arbitrary point from the Pareto frontier, yields the following curve in real-space.

```{r}
best <- subset(pareto.points, pred.ad > 0.75 & pred.ad < 0.78)

best.transform <- data.frame( y = yyy^best$py, x = xxx^best$px)
best.lm <- lm(y~x, data = best.transform)

b0 <- coef(best.lm)[1]
b1 <- coef(best.lm)[2]

fit.curve <- function(x){
  (b1*(x^best$px) + b0)^(1/best$py)
}

g <- ggplot() + ggtitle("Curve Fit")
g <- g + xlab("x")
g <- g + ylab("y")
g <- g + stat_function(aes(x = xxx), fun = fit.curve, 
                       colour = "red", lwd = 2, alpha = 0.5)
g <- g + geom_point(aes(x = xxx, y = yyy))
g
```

The selected power transformations on $x$ and $y$ are: 
```{r, results = 'asis'}
power.transforms <- data.frame(power.of.y = best$py,
                               power.of.x = best$px)

pander(power.transforms, caption = "")
```
<br><hr>
Finally, the model parameters and performance in the transformed space:
```{r}
pander(summary(best.lm), caption = "")
```

```{r}
final.set <- data.frame(observations = yyy,
                        predictions = fit.curve(xxx))

g <- ggplot(final.set, 
            aes(x = predictions, y = observations)) 
g <- g + xlim(0, 45) + ylim(0, 45) + geom_abline(color = "blue")
g + geom_jitter()

```

<hr>

# Appendix

## Reproducibility Information
```{r}
pander(sessionInfo())
```
